## API를 활용한 크롤링을 보여드리고자 합니다.
> 보통 API 크롤링을 하면 페이지 당 20개의 정보만 보여주어 모든 정보를 가져오려면 어떻게 해야할까 라는 고민을 많이 합니다.
> 
> 보통은 페이지 파라미터를 활용하여 해결합니다.


## Case1. 산림청 - 산정보 서비스
*https://www.data.go.kr/data/15058662/openapi.do*

- 우선적으로 API키를 받아옵니다.
- 요청가능한 파라미터를 확인합니다. 페이지 파라미터가 명시적으로 나와있지는 않지만 URL 내부에 존재하네요. 페이지 파라미터를 반복문에 넣어 정보를 수집합니다. (산명 파라미터는 옵션으로, 이를 넣지 않았을 때 전체정보가 수집된다는 것을 파악할 수 있는 센스가 필요합니다)

![image](https://user-images.githubusercontent.com/28617435/122553017-05f93780-d072-11eb-8cdf-c57cf0fde2e6.png)



## Case2. 산림청 - 산 정보 조회
*https://www.data.go.kr/data/15058682/openapi.do*

- 우선적으로 API 키를 받아옵니다.
- 요청가능한 파라미터를 확인합니다. 페이지 파라미터는 URL 내부에 존재합니다. 

![image](https://user-images.githubusercontent.com/28617435/122551927-9a629a80-d070-11eb-9c4f-f09d302da2cd.png)

- 보통 API의 경우 참고문서가 존재합니다. 해당 참고문서의 맨 뒤에 가면 지역정보, 계절코드, 주제코드 등이 존재합니다. 이 값들을 반복문을 통해 하나씩 대입하면 원하는 정보를 필터링하여 수집할 수 있습니다.
> 
> 최대한 참고문서에서 **범위가 정해진 자료**를 활용하고자 하면 더욱 쉽게 크롤링을 할 수 있습니다. 제 코드도 마찬가지로 계절코드로 진행하였습니다.
> 
![image](https://user-images.githubusercontent.com/28617435/122552124-e1509000-d070-11eb-836f-481588ea2737.png)

